{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2a3f9e3",
   "metadata": {},
   "source": [
    "# Setup Web Automation with Selenium\n",
    "Subway Surfers is available on Poki.com. Using Selenium to launch the game and interact with it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a04dc629",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# Setup browser driver\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://poki.com/en/g/subway-surfers\")\n",
    "time.sleep(5)  # Allow game page to load\n",
    "\n",
    "# Ensure the game window is focused\n",
    "game_window = driver.find_element(\"tag name\", \"body\")\n",
    "game_window.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a07488",
   "metadata": {},
   "source": [
    "# Capture Hand Gestures Map Gestures and Integrate Everything\n",
    "\n",
    "Using OpenCV & MediaPipe to detect fingers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4914d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¹ Starting video capture thread...\n",
      "ğŸš€ Gesture detection started. Press 'q' in the OpenCV window to quit.\n",
      "ğŸ–ï¸ Detected 3 fingers. Action: RIGHT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 3 fingers. Action: RIGHT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 1 fingers. Action: UP\n",
      "ğŸ–ï¸ Detected 1 fingers. Action: UP\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 1 fingers. Action: UP\n",
      "ğŸ–ï¸ Detected 1 fingers. Action: UP\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 1 fingers. Action: UP\n",
      "ğŸ–ï¸ Detected 1 fingers. Action: UP\n",
      "ğŸ–ï¸ Detected 1 fingers. Action: UP\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 3 fingers. Action: RIGHT\n",
      "ğŸ–ï¸ Detected 2 fingers. Action: DOWN\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n",
      "ğŸ–ï¸ Detected 4 fingers. Action: LEFT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# --- Configuration ---\n",
    "WEBCAM_RESOLUTION = (1280, 720) # Use a higher resolution for better accuracy\n",
    "CONFIDENCE_THRESHOLD = 0.8     # Higher confidence to reduce false positives\n",
    "ACTION_COOLDOWN = 0.35         # Seconds between actions for smoother control\n",
    "\n",
    "# --- MediaPipe Hands Initialization ---\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=CONFIDENCE_THRESHOLD,\n",
    "    min_tracking_confidence=CONFIDENCE_THRESHOLD\n",
    ")\n",
    "mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "# Frame queue for communication between threads\n",
    "frame_queue = queue.Queue(maxsize=1)\n",
    "\n",
    "def video_capture_thread():\n",
    "    \"\"\"\n",
    "    Dedicated thread to capture frames from the webcam as fast as possible.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“¹ Starting video capture thread...\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, WEBCAM_RESOLUTION[0])\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, WEBCAM_RESOLUTION[1])\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # If the queue is full, remove the old frame and add the new one\n",
    "        if frame_queue.full():\n",
    "            frame_queue.get_nowait()\n",
    "        frame_queue.put(frame)\n",
    "    cap.release()\n",
    "    print(\"Video capture thread finished.\")\n",
    "\n",
    "def perform_action(finger_count):\n",
    "    \"\"\"Maps finger count to a keyboard press and prints the action.\"\"\"\n",
    "    actions_map = {\n",
    "        1: 'up',    # Jump\n",
    "        2: 'down',  # Roll\n",
    "        3: 'right', # Move Right\n",
    "        4: 'left',  # Move Left\n",
    "    }\n",
    "    action = actions_map.get(finger_count)\n",
    "    if action:\n",
    "        print(f\"ğŸ–ï¸ Detected {finger_count} fingers. Action: {action.upper()}\")\n",
    "        pyautogui.press(action)\n",
    "\n",
    "def main_gesture_loop():\n",
    "    \"\"\"\n",
    "    Main loop to process frames, detect gestures, and control the game.\n",
    "    \"\"\"\n",
    "    last_action_time = 0\n",
    "\n",
    "    # Start the video capture in a separate thread\n",
    "    capture_thread = threading.Thread(target=video_capture_thread, daemon=True)\n",
    "    capture_thread.start()\n",
    "    time.sleep(2) # Give the camera time to initialize\n",
    "\n",
    "    print(\"ğŸš€ Gesture detection started. Press 'q' in the OpenCV window to quit.\")\n",
    "\n",
    "    while True:\n",
    "        if frame_queue.empty():\n",
    "            continue\n",
    "\n",
    "        frame = frame_queue.get()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(img_rgb)\n",
    "\n",
    "        finger_count = 0\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "\n",
    "            # Draw landmarks for visualization\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # --- Refined Finger Counting Logic ---\n",
    "            finger_tip_ids = [8, 12, 16, 20] # Tips of index, middle, ring, pinky\n",
    "            fingers_up = 0\n",
    "\n",
    "            # Check four fingers (up/down)\n",
    "            for tip_id in finger_tip_ids:\n",
    "                if hand_landmarks.landmark[tip_id].y < hand_landmarks.landmark[tip_id - 2].y:\n",
    "                    fingers_up += 1\n",
    "\n",
    "            # Check thumb (left/right) - more robust for horizontal hand\n",
    "            if hand_landmarks.landmark[4].x < hand_landmarks.landmark[3].x:\n",
    "                fingers_up += 1\n",
    "\n",
    "            finger_count = fingers_up\n",
    "\n",
    "            # --- Action Cooldown Logic ---\n",
    "            current_time = time.time()\n",
    "            if current_time - last_action_time > ACTION_COOLDOWN:\n",
    "                perform_action(finger_count)\n",
    "                last_action_time = current_time\n",
    "\n",
    "            # Display finger count on the frame\n",
    "            cv2.putText(frame, f\"Fingers: {finger_count}\", (30, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 0, 0), 3, cv2.LINE_AA)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow(\"Gesture Controller - Press 'q' to quit\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"ğŸ›‘ Gesture detection stopped.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_gesture_loop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
